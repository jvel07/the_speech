import numpy as np
import pandas as pd
import os
from common import util


from sklearn import preprocessing


# work_dir = 'C:/Users/Win10/PycharmProjects/the_speech/data/pcgita/' # windows machine
work_dir = '/media/jose/hk-data/PycharmProjects/the_speech/data/'  # ubuntu machine
# work_dir2 = 'D:/VHD'




# Encoding labels to numbers
def encode_labels(_y, list_labels):
    le = preprocessing.LabelEncoder()
    le.fit(list_labels)
    y = le.transform(_y)
    y = y.reshape(-1, 1)
    return np.squeeze(y), le


# loads the data given the number of gaussians, the name of the task and the type of feature.
# Used for small datasets; loads single file containing training features.
# E.g.: (4, 'monologue', 'fisher') or 'ivecs'
# example: train/fisher-23mf-0del-2g-train.fisher
def load_data_single(gauss, task, feat_type, n_feats, n_deltas, list_labels):
    if (feat_type == 'fisher') or (feat_type == 'ivecs') or (feat_type == 'xvecs'):
        # Set data directories
        file_train = work_dir + '{}/{}/{}-{}mf-{}del-{}-{}.{}'.format(task, task, feat_type, n_feats, n_deltas, gauss, task, feat_type)
        file_lbl_train = work_dir + '{}/labels/labels.csv'.format(task)

        # Load data
        X_train = np.loadtxt(file_train)
        df_labels = pd.read_csv(file_lbl_train, dtype=str)
        Y_train, encoder = encode_labels(df_labels.label.values, list_labels)

        return X_train, Y_train.ravel()
    else:
        raise ValueError("'{}' is not a supported feature representation, please enter 'ivecs' or 'fisher'.".format(feat_type))


# E.g.: (4, 'mask', 'fisher') or 'ivecs'
# example: train/fisher-23mf-0del-2g-train.fisher
# loads data (files' name-format that were generated by this SW) existing in the folders "train", "dev" and "test".
# Format of the data labels required and file with the following headers:
#    'file_name     label'  Example: 'file_name     label'
#    'recording.wav label'. Example: 'train_0001.wav True', 'train_0002.wav 2 False', ...
def load_data_compare2021(gauss, task, feat_type, n_feats, list_labels):
    list_datasets = ['train', 'dev', 'test']  # names for the datasets
    dict_data = {}
    if (feat_type[0] == 'fisher') or (feat_type[0] == 'ivecs') or (feat_type[0] == 'xvecs'):
        # Load train, dev, test
        for item in list_datasets:
            # Set data directories
            file_dataset = work_dir + '{0}/{1}/{2}-{3}{4}-{5}del-{6}-{7}.{8}'.format(task, item, feat_type[0], n_feats, feat_type[1],
                                                                            feat_type[2], str(gauss), item, feat_type[0])
            # Load datasets
            dict_data['x_'+item] = np.loadtxt(file_dataset)
            # Load labels
            file_lbl_train = work_dir + '{}/labels/{}_orig.csv'.format(task, item) # set data dir
            df = pd.read_csv(file_lbl_train)
            df_labels = df[df['filename'].str.match(item)]
            df_labels = df_labels.label.replace('?', list_labels[0])
            dict_data['y_'+item], enc = encode_labels(df_labels.values, list_labels) #  binarizing labels
        return dict_data['x_train'], dict_data['x_dev'], dict_data['x_test'], dict_data['y_train'], dict_data['y_dev'], file_dataset, enc
    else:
        raise ValueError("'{}' is not a supported feature representation, please enter 'ivecs' or 'fisher'.".format(feat_type[0]))


# same as the above one but here test labels are known
def load_data_full_2(gauss, task, feat_info, list_labels):
    list_datasets = ['train', 'dev', 'test']  # names for the datasets
    dict_data = {}
    if (feat_info[0] == 'fisher') or (feat_info[0] == 'ivecs') or (feat_info[0] == 'xvecs'):
        # Load train, dev, test
        for item in list_datasets:
            # Set data directories
            file_dataset = work_dir + '{0}/{1}/{2}-{3}{4}-{5}del-{6}-{7}.{2}'.format(task, item, feat_info[0], feat_info[3], feat_info[1],
                                                                            feat_info[2], str(gauss), item, feat_info[0])
            # Load datasets
            dict_data['x_'+item] = np.loadtxt(file_dataset)
            # Load labels
            file_lbl_train = work_dir + '{}/labels/labels.csv'.format(task) # set data dir
            df = pd.read_csv(file_lbl_train)
            df_labels = df[df['file_name'].str.match(item)]
            # df_labels = df_labels.label.replace('?', list_labels[0])
            dict_data['y_'+item], enc = encode_labels(df_labels.label.values, list_labels) #  binarizing labels
        return dict_data['x_train'], dict_data['x_dev'], dict_data['x_test'], dict_data['y_train'], dict_data['y_dev'], dict_data['y_test'], file_dataset, enc
    else:
        raise ValueError("'{0}' is not a supported feature representation, please enter 'ivecs', 'fisher', or 'xvecs'.".format(feat_info[0]))


# Create labels from the name of the wavs (specific for compare challenge 2021)
# E.g. file name: 001_train_00001.wav where the 3rd character is the code of the label (1 in this case)
def generate_lbl_from_wav_names(path_to_wavs, dest_path, labels_dict):
    list_audios = os.listdir(path_to_wavs)
    list_audios.sort()
    new_list = []
    for i in list_audios:
        label_code = i[2]
        label_cat = labels_dict[int(label_code)]
        wav_name = i[4:]
        new_list.append(wav_name + "," + label_cat)
    np.savetxt('{}/{}.csv'.format(dest_path, os.path.basename(path_to_wavs)), new_list, delimiter=',', fmt='%s')
    return new_list


def load_data_alternate(gauss, task):
    # Set data directories
    file_train = work_dir + 'alternate/vlfeats.mfccs.{}.all.{}.cv.txt'.format(task, gauss)
    file_lbl_train = work_dir + 'labels/labels_{}.txt'.format(task)

    # Load data
    X_train = np.loadtxt(file_train, delimiter=',')
    df_labels = pd.read_csv(file_lbl_train, delimiter=' ', header=None)
    df_labels.columns = ['wav', 'label']
    Y_train = encode_labels(df_labels.label.values)

    return X_train, Y_train.ravel()



def load_data_compare():
    # Task
    task_name = 'ComParE2020_Mask'  # os.getcwd().split('/')[-2]
    classes = ['clear', 'mask']

    # Enter your team name HERE
    team_name = 'baseline'

    # Enter your submission number HERE
    submission_index = 1

    # Option
    show_confusion = True  # Display confusion matrix on devel

    # Configuration
    feature_set = 'DeepSpectrum_resnet50'  # For all available options, see the dictionary feat_conf
    complexities = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0]  # SVM complexities (linear kernel)

    # Mapping each available feature set to tuple (number of features, offset/index of first feature, separator, header option)
    feat_conf = {'ComParE': (6373, 1, ';', 'infer'),
                 'BoAW-125': (250, 1, ';', None),
                 'BoAW-250': (500, 1, ';', None),
                 'BoAW-500': (1000, 1, ';', None),
                 'BoAW-1000': (2000, 1, ';', None),
                 'BoAW-2000': (4000, 1, ';', None),
                 'auDeep-30': (1024, 2, ',', 'infer'),
                 'auDeep-45': (1024, 2, ',', 'infer'),
                 'auDeep-60': (1024, 2, ',', 'infer'),
                 'auDeep-75': (1024, 2, ',', 'infer'),
                 'auDeep-fused': (4096, 2, ',', 'infer'),
                 'DeepSpectrum_resnet50': (2048, 1, ',', 'infer')}
    num_feat = feat_conf[feature_set][0]
    ind_off = feat_conf[feature_set][1]
    sep = feat_conf[feature_set][2]
    header = feat_conf[feature_set][3]

    # Path of the features and labels
    work_dir = '/media/jose/hk-data/PycharmProjects/the_speech/data/'  # ubuntu machine
    features_path = work_dir + 'mask' + '/features/'
    label_file = work_dir + 'mask' + '/labels/labels.csv'

    # Start
    print('\nRunning ' + task_name + ' ' + feature_set + ' baseline ... (this might take a while) \n')

    # Load features and labels
    X_train = pd.read_csv(features_path + task_name + '.' + feature_set + '.train.csv', sep=sep, header=header,
                          usecols=range(ind_off, num_feat + ind_off), dtype=np.float32).values
    X_devel = pd.read_csv(features_path + task_name + '.' + feature_set + '.devel.csv', sep=sep, header=header,
                          usecols=range(ind_off, num_feat + ind_off), dtype=np.float32).values
    X_test = pd.read_csv(features_path + task_name + '.' + feature_set + '.test.csv', sep=sep, header=header,
                         usecols=range(ind_off, num_feat + ind_off), dtype=np.float32).values

    df_labels = pd.read_csv(label_file)
    y_train = df_labels['label'][df_labels['file_name'].str.startswith('train')].values
    y_devel = df_labels['label'][df_labels['file_name'].str.startswith('devel')].values

    y_train, encoder = encode_labels(y_train, ['mask', 'clear'])
    y_devel, encoder = encode_labels(y_devel, ['mask', 'clear'])

    return X_train, X_devel, X_test, y_train, y_devel, encoder